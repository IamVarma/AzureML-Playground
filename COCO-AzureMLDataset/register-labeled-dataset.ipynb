{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "task_type = 'OBJECT_DETECTION'\n",
    "dataset_name = 'MyDatasetnew2'\n",
    "jsonline_files_path = os.path.join(os.getcwd(), 'JsonLines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pathlib\n",
    "\n",
    "TAG_CREATED_BY = 'labelingCreatedBy'\n",
    "TAG_PROJECT_TYPE = 'labelingProjectType'\n",
    "TAG_SOURCE_DATASTORE_NAME = 'SourceDatastoreName'\n",
    "TAG_SOURCE_RELATIVE_PATH = 'SourceRelativePath'\n",
    "TAG_LABEL_NAME = 'labelingLabelName'\n",
    "\n",
    "Labeling_Project_Type = {\n",
    "    'IMAGE_CLASSIFICATION': 'Image Classification Multi-class',\n",
    "    'IMAGE_MULTI_LABEL_CLASSIFICATION': 'Image Classification',\n",
    "    'OBJECT_DETECTION': 'Object Identification (Bounding Box)',\n",
    "    'IMAGE_INSTANCE_SEGMENTATION': 'Instance Segmentation',\n",
    "    'TEXT_CLASSIFICATION': 'Text Classification Multi-class',\n",
    "    'TEXT_MULTI_LABEL_CLASSIFICATION': 'Text Classification Multi-label',\n",
    "    'TEXT_NAMED_ENTITY_RECOGNITION': 'Text Named Entity Recognition'\n",
    "    }\n",
    " \n",
    "URL_SCHEME = 'AmlDatastore:/'\n",
    "URL_KEY = 'image_url'\n",
    "LABEL_KEY = 'label'\n",
    "\n",
    "\n",
    "class DatasetTagsGenerator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labelSet = set()\n",
    "        self.tags = {TAG_CREATED_BY: 'Labeled Dataset Registration NoteBook (v.4)',\n",
    "                     TAG_PROJECT_TYPE: None,\n",
    "                     TAG_SOURCE_DATASTORE_NAME: None,\n",
    "                     TAG_SOURCE_RELATIVE_PATH: None,\n",
    "                     TAG_LABEL_NAME: []}\n",
    "\n",
    "    def get_tags_from_jsonl_files(self, jsonl_file_folder: str, task_type: str) -> dict():\n",
    "        if not os.path.exists(jsonl_file_folder):\n",
    "            raise Exception(\"JsonLine folder {} not found.\".format(jsonl_file_folder))\n",
    "\n",
    "        for root, _, files in os.walk(jsonl_file_folder):\n",
    "            for file in files:\n",
    "                if pathlib.PurePath(file).suffix == '.jsonl':\n",
    "                    with jsonlines.open(os.path.join(root, file)) as reader:\n",
    "                        for json_line in reader:\n",
    "                            self._populate_label_names(json_line)\n",
    "                            self._populate_source_relative_path(json_line[URL_KEY])\n",
    "\n",
    "        p = pathlib.PurePath(self.tags[TAG_SOURCE_RELATIVE_PATH])\n",
    "        p = p.relative_to(URL_SCHEME)\n",
    "\n",
    "        self.tags[TAG_PROJECT_TYPE] = Labeling_Project_Type[task_type]\n",
    "        self.tags[TAG_SOURCE_DATASTORE_NAME] = p.parts[0]\n",
    "        self.tags[TAG_SOURCE_RELATIVE_PATH] = str(pathlib.PurePosixPath(*list(p.parts[1:]))) + \"/**\"\n",
    "        self.tags[TAG_LABEL_NAME] = list(self.labelSet)\n",
    "        return self.tags\n",
    "\n",
    "    def _populate_label_names(self, json_line:str):\n",
    "\n",
    "        if type(json_line[LABEL_KEY]) is list:\n",
    "            for label in json_line[LABEL_KEY]:\n",
    "                if type(label) is dict:\n",
    "                    self.labelSet.add(label[LABEL_KEY])\n",
    "                else:\n",
    "                    self.labelSet.add(label)\n",
    "        else:\n",
    "            self.labelSet.add(json_line[LABEL_KEY])\n",
    "\n",
    "    def _populate_source_relative_path(self, image_url:str):\n",
    "        if self.tags[TAG_SOURCE_RELATIVE_PATH] is None:\n",
    "            self.tags[TAG_SOURCE_RELATIVE_PATH] = image_url\n",
    "        else:\n",
    "            self.tags[TAG_SOURCE_RELATIVE_PATH] = os.path.commonpath([self.tags[TAG_SOURCE_RELATIVE_PATH], image_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "#Uploading and Registering the Dataset with AzureML \n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"<TenantID>\")\n",
    "ws = Workspace.get(name='<workspace-name>',\n",
    "            subscription_id='<sub-id>',\n",
    "            resource_group='<resource-group>',\n",
    "            location='<location>',\n",
    "            cloud='AzureCloud',\n",
    "            auth=interactive_auth\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading c:\\Users\\varmag\\Documents\\AzureML-Playground\\COCO-AzureMLDataset\\JsonLines\\LabeledData.jsonl\n",
      "Uploaded c:\\Users\\varmag\\Documents\\AzureML-Playground\\COCO-AzureMLDataset\\JsonLines\\LabeledData.jsonl, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "def_blob_store = ws.get_default_datastore()\n",
    "path_on_datastore = pathlib.PurePosixPath('/','Labeling', 'datasets', dataset_name)\n",
    "jsonline_files = [os.path.join(jsonline_files_path, file) for _, _, files in os.walk(jsonline_files_path) for file in files if pathlib.PurePath(file).suffix == '.jsonl']\n",
    "dataset_source = def_blob_store.upload_files(jsonline_files, target_path = str(path_on_datastore), overwrite = True, show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory, DataType\n",
    "dataset_list = [k for k in ws.datasets.keys()]\n",
    "if dataset_name in dataset_list:\n",
    "    ouput_labeled_dataset = ws.datasets.get(dataset_name)\n",
    "    print('Dataset \"{}\" has been registered in workspace \"{}\", please provide a different dataset name.'.format(dataset_name, ws.name))\n",
    "else:\n",
    "    tagsGenerator = DatasetTagsGenerator()\n",
    "    tags = tagsGenerator.get_tags_from_jsonl_files(jsonline_files_path, task_type)\n",
    "    output_tabular_dataset = TabularDatasetFactory.from_json_lines_files(path = dataset_source, set_column_types = {'image_url': DataType.to_stream(ws)} )\n",
    "    output_tabular_dataset = output_tabular_dataset.register(workspace = ws, name = dataset_name, tags = tags)\n",
    "\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1e46b962734b5bdd5018c2a27a84e3e4d88af85755b7fe58cb21f5d4d4cf12a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
